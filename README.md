# Mad Spark Alt - Hypothesis-Driven Analysis & Evolution System

A hypothesis-driven analysis system based on the QADI methodology from "Shin Logical Thinking", featuring AI-powered hypothesis generation, evaluation, and genetic evolution to find optimal solutions.

## Features

- üéØ **True QADI Methodology**: Hypothesis-driven consulting approach
  - **Q**: Extract the core question from any input
  - **A**: Generate hypotheses to answer the question
  - **D**: Evaluate and determine the best answer
  - **I**: Verify with real-world examples
- üß¨ **Genetic Evolution**: Evolve hypotheses using AI-powered genetic algorithms
- üìä **Unified Evaluation**: 5-criteria scoring (novelty, impact, cost, feasibility, risks)
- üå°Ô∏è **Temperature Control**: Adjust creativity level for hypothesis generation
- ‚ö° **Phase-Optimized**: Each QADI phase uses optimal AI parameters
- üîå **Extensible**: Plugin system for custom evaluators

## Installation

```bash
# Clone the repository
git clone https://github.com/TheIllusionOfLife/mad_spark_alt.git
cd mad_spark_alt

# Install with uv (recommended)
uv sync

# Or install with pip
pip install -e .
```

## Quick Start

### Setup

```bash
# Create .env file with your API key (REQUIRED for meaningful results)
echo "GOOGLE_API_KEY=your_key_here" > .env

# Or use other providers
echo "OPENAI_API_KEY=your_key_here" >> .env
echo "ANTHROPIC_API_KEY=your_key_here" >> .env
```

### Generate Ideas with QADI

```bash
# NEW: Hypothesis-driven QADI analysis
uv run python qadi_hypothesis.py "How can we reduce plastic waste?"

# Adjust creativity with temperature (0.0-2.0)
uv run python qadi_hypothesis.py "New product ideas" --temperature 1.5

# Show detailed evaluation scores
uv run python qadi_hypothesis.py "Climate solutions" --verbose

# Legacy multi-agent version (being phased out)
uv run python qadi_simple_multi.py "How can we reduce plastic waste?"
```

### Example Prompts to Try

**Business & Innovation**
- "How can small businesses compete with large corporations in the digital age?"
- "What innovative business models could address climate change?"
- "How might we revolutionize remote work collaboration?"

**Technology & Society**
- "How can AI improve healthcare accessibility in rural areas?"
- "What are creative solutions to digital privacy concerns?"
- "How might we bridge the digital divide in education?"

**Environmental & Sustainability**
- "How can cities become carbon-neutral by 2030?"
- "What innovative approaches could solve ocean plastic pollution?"
- "How might vertical farming transform urban food systems?"

**Creative & Abstract**
- "What if gravity worked differently on weekends?"
- "How would society change if we could share dreams?"
- "Design a new sport for zero-gravity environments"

### CLI Tools

```bash
# Evaluate idea creativity
uv run mad-spark evaluate "The AI dreamed of electric sheep in quantum meadows"

# Evaluate with verbose output
uv run mad-spark evaluate "Blockchain social media platform" --verbose

# Compare multiple ideas
uv run mad-spark compare "Business communication" -r "Traditional email" -r "AI video messages" -r "Holographic cards"

# Batch evaluate multiple files
echo "Smart mirrors with personalized compliments" > idea1.txt
uv run mad-spark batch-evaluate idea1.txt idea2.txt

# List available evaluators
uv run mad-spark list-evaluators

# Run genetic evolution demo
uv run python examples/evolution_demo.py

# IMPORTANT: Evolution features - see below for the powerful evolution system!
```

### Python API

```python
import asyncio
from mad_spark_alt.core.simple_qadi_orchestrator import SimpleQADIOrchestrator

async def run_analysis():
    orchestrator = SimpleQADIOrchestrator(temperature_override=1.2)
    result = await orchestrator.run_qadi_cycle(
        user_input="How can we reduce plastic waste?",
        context="Focus on practical, scalable solutions"
    )
    
    print(f"Core Question: {result.core_question}")
    print(f"\nBest Answer: {result.final_answer}")
    print(f"\nAction Plan:")
    for i, action in enumerate(result.action_plan):
        print(f"{i+1}. {action}")

asyncio.run(run_analysis())
```

For detailed API examples and advanced usage patterns, see [DEVELOPMENT.md](DEVELOPMENT.md).

## üß¨ Genetic Evolution System

**Evolve your hypotheses through AI-powered genetic algorithms!**

The evolution system takes the hypotheses generated by QADI and evolves them over multiple generations to find optimal solutions:

```bash
# Evolve ideas with default settings
uv run mad-spark evolve "How can we reduce food waste?"

# Quick evolution (2 generations, smaller population)
uv run mad-spark evolve "Climate solutions" --quick

# Custom evolution parameters
uv run mad-spark evolve "New product ideas" \
  --generations 5 \
  --population 20 \
  --temperature 1.5

# Save results to file
uv run mad-spark evolve "Business strategies" --output results.json
```

### How Evolution Works

1. **Initial Population**: QADI generates hypotheses as the starting population
2. **Fitness Evaluation**: Each hypothesis is scored on 5 criteria:
   - **Novelty** (20%): How innovative/unique is the approach?
   - **Impact** (30%): What level of positive change will it create?
   - **Cost** (20%): Resource efficiency (lower cost = higher score)
   - **Feasibility** (20%): How practical is implementation?
   - **Risks** (10%): Risk level (lower risk = higher score)
3. **Selection**: Best hypotheses are selected for breeding
4. **Crossover**: Combine elements from two parent ideas (75% rate)
5. **Mutation**: Introduce variations for diversity (15% rate)
6. **Next Generation**: Repeat until optimal solutions emerge

### Evolution Features

- **Parallel Evaluation**: Evaluates up to 8 ideas simultaneously
- **Smart Caching**: 50-70% reduction in API calls through result caching
- **Checkpointing**: Save/resume evolution state for long runs
- **Diversity Preservation**: Prevents convergence to local optima
- **Real-time Progress**: Track fitness improvements and cache performance

### Example Evolution Output

```
üß¨ Evolution Pipeline
Problem: How can we reduce plastic waste in oceans?
Generations: 5 | Population: 12 | Temperature: 0.8

‚úÖ Generated 3 initial hypotheses
üí∞ LLM Cost: $0.0234

‚úÖ Evolution completed in 45.2s

üèÜ Top Evolved Ideas:
1. Autonomous ocean drones with ML-powered plastic detection... (Fitness: 0.892)
2. Blockchain-tracked plastic credits incentivizing cleanup... (Fitness: 0.847)
3. Bioengineered bacteria that safely decompose ocean plastic... (Fitness: 0.823)

üìä Results:
‚Ä¢ Fitness improvement: 47.3%
‚Ä¢ Ideas evaluated: 60
‚Ä¢ Best from generation: 4

üíæ Cache Performance:
‚Ä¢ Hit rate: 65%
‚Ä¢ LLM calls saved: 39
```

## How QADI Works

### The Hypothesis-Driven Process

1. **Q (Question)**: Extract the core question
   - Input: "I want to reduce employee turnover"
   - Output: "What factors are causing high-value employees to leave?"

2. **A (Abduction)**: Generate hypotheses
   - H1: "Lack of career growth opportunities"
   - H2: "Poor work-life balance"
   - H3: "Uncompetitive compensation"

3. **D (Deduction)**: Evaluate and answer
   - Scores each hypothesis on 5 criteria
   - Determines: "Implement career development programs"
   - Provides concrete action plan

4. **I (Induction)**: Verify with examples
   - Google's 20% time ‚Üí 50% turnover reduction
   - Hospital residency programs ‚Üí 40% better retention
   - Confirms answer is broadly applicable

### Temperature Control

Adjust the creativity level of hypothesis generation:
- `0.0-0.5`: Conservative, practical hypotheses
- `0.6-1.0`: Balanced creativity (default: 0.8)
- `1.1-2.0`: Highly creative, unconventional ideas

## System Architecture

**Architecture**: Hypothesis-driven analysis with unified evaluation and genetic evolution

**Key Components**:
- **Simple QADI Orchestrator**: Clean implementation of the 4-phase process
- **Universal Prompts**: Single set of prompts for all input types
- **Unified Evaluator**: Consistent 5-criteria scoring system
- **Evolution Engine**: AI-powered genetic algorithms
  - **Smart Operators**: LLM-based crossover and mutation
  - **Result Caching**: 50-70% reduction in API calls
  - **Checkpointing**: Save/resume evolution state
  - **Real-time Monitoring**: Track progress and performance
- **Phase Optimization**: Each QADI phase uses optimal hyperparameters

For detailed architecture documentation, see [DEVELOPMENT.md](DEVELOPMENT.md).

## Extending the System

The system supports custom agents and evaluators through a plugin architecture:

- **Custom Thinking Agents**: Implement `ThinkingAgentInterface` for new reasoning methods
- **Custom Evaluators**: Implement `EvaluatorInterface` for new creativity metrics
- **Dynamic Registration**: Components auto-register when imported

For detailed extension guides and examples, see [DEVELOPMENT.md](DEVELOPMENT.md).

## Development

```bash
# Install development dependencies
uv sync --dev

# Run tests
uv run pytest

# Type checking
uv run mypy src/

# Code formatting
uv run black src/ tests/ && uv run isort src/ tests/
```

For comprehensive development guidelines, testing patterns, and contribution workflow, see [DEVELOPMENT.md](DEVELOPMENT.md).

## Session Handover

### Last Updated: 2025-07-23 08:45 UTC

#### Recently Completed
- ‚úÖ **PR #44 [MERGED]**: Centralize cost tracking and enhance CI testing
  - **Major Achievement**: Fixed all critical cost calculation issues identified in deep review
  - Centralized cost calculation in `cost_utils.py` eliminating duplication across 8+ modules
  - Added `calculate_llm_cost_from_config()` to use ModelConfig costs directly (fixes model name mismatch)
  - Enhanced test coverage with comprehensive regression test suite (346 lines)
  - Fixed brittle token parsing with prioritized lookup pattern
  - Improved CI/CD with coverage reporting and test artifacts
  - Applied systematic PR review feedback resolution using 4-phase protocol
  - **Result**: All 158 tests pass, complete CI success, production-ready cost tracking
- ‚úÖ **PR #42 [MERGED]**: Fixed critical issues from PR #40 deep review
- ‚úÖ **PR #40 [MERGED]**: Implemented true QADI hypothesis-driven methodology

#### Next Priority Tasks
1. **Fix Method Signatures in benchmarks.py** (HIGH PRIORITY)
   - Source: Pending from PR #38 review
   - Context: Method signatures don't match parent class interface
   - Approach: Update to match ThinkingAgentInterface expected signatures

2. ~~**Cost Estimation Centralization** (COMPLETED in PR #44)~~

3. ~~**Add Regression Tests for Cost Tracking** (COMPLETED in PR #44)~~

4. **Performance Optimization** (MEDIUM PRIORITY)
   - Source: Production readiness evaluation
   - Context: With cost tracking centralized, focus on performance improvements
   - Approach: Profile critical paths, optimize hot loops, add caching where beneficial

#### Known Issues / Blockers
- None currently - all CI passing, all reviewer feedback addressed

#### Session Learnings
- **Cost Calculation Architecture**: Centralized cost tracking in dedicated module eliminates duplication and ensures consistency
- **PR Review Systematic Approach**: 4-phase protocol (discover ‚Üí extract ‚Üí verify ‚Üí process) successfully found all reviewer feedback across 3 GitHub API endpoints
- **CI Failure Diagnosis**: Fast failures (<2 minutes) across all Python versions indicate formatting/import issues, not test problems
- **Black Formatting**: Always run `black --check` locally before push - CI catches formatting violations that cause failures
- **Model Name Mismatch Bug**: Using hardcoded model name mappings causes incorrect cost calculations - use ModelConfig values directly
- **Float Precision Testing**: Use `pytest.approx()` for cost calculations to handle floating-point precision issues
- **DRY Implementation**: Complete centralization requires updating ALL providers to use central functions, not just adding the central module
- **Test Coverage Value**: Comprehensive regression tests (346 lines) catch architectural flaws and prevent future regressions

## Documentation

- **[DEVELOPMENT.md](DEVELOPMENT.md)**: Development setup, architecture, coding standards, and API reference
- **[RESEARCH.md](RESEARCH.md)**: Academic background, QADI methodology, and research foundations
- **[SESSIONS.md](SESSIONS.md)**: Development session history and progress tracking

## Contributing

1. Fork the repository
2. Create a feature branch
3. Add tests for new functionality
4. Ensure all tests pass
5. Submit a pull request

See [DEVELOPMENT.md](DEVELOPMENT.md) for detailed contribution guidelines.

## License

MIT License - see [LICENSE](LICENSE) for details.
